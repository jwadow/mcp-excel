# Архитектура MCP-сервера для работы с Excel

## Лицензия и правовые аспекты

**Проект распространяется под лицензией GNU Affero General Public License v3.0 (AGPL-3.0)**

### Почему AGPL v3?

AGPL v3 выбрана для защиты открытого характера проекта при использовании в сетевом режиме:

- **Защита от SaaS-эксплуатации:** Если кто-то запускает модифицированную версию сервера по сети (SSE режим), они обязаны предоставить исходный код всех изменений
- **Сохранение улучшений в сообществе:** Все модификации и расширения должны оставаться открытыми
- **Копилефт для сетевых сервисов:** В отличие от GPL, AGPL закрывает "сетевую лазейку"

### Требования к зависимостям

**Критическое правило:** Все используемые библиотеки должны иметь лицензии, совместимые с AGPL v3.

**Совместимые лицензии:**
- MIT License
- BSD License (2-Clause, 3-Clause)
- Apache License 2.0
- Python Software Foundation License
- LGPL v2.1, v3
- GPL v2, v3
- AGPL v3

**Несовместимые лицензии (запрещены):**
- Proprietary/Commercial licenses
- Creative Commons Non-Commercial (CC BY-NC)
- Любые лицензии с ограничениями на коммерческое использование
- Лицензии с патентными ограничениями, несовместимыми с AGPL

**Процедура добавления новой зависимости:**
1. Проверить лицензию библиотеки
2. Убедиться в совместимости с AGPL v3
3. Документировать лицензию в `pyproject.toml` или `requirements.txt`
4. При сомнениях — консультироваться с юристом или использовать альтернативу

---

## 1. Философия проекта

### 1.1. Принцип математических примитивов

Архитектура сервера построена на концепции **атомарных операций** — минимального набора базовых функций, из которых можно составить любой сложный анализ данных. Подобно тому, как вся математика строится на операциях сложения, умножения, возведения в степень и извлечения корня, MCP-сервер предоставляет набор примитивов для работы с табличными данными.

**Ключевой принцип:** Агент не должен получать сырые данные таблицы в свой контекст. Вместо этого он комбинирует вызовы атомарных операций, получая только результаты вычислений.

**Пример композиции:**
```
Задача: "Найти среднюю сумму заказов клиента 'Ромашка' за последний квартал"

Декомпозиция агентом:
1. get_unique_values(column="Клиент") → узнать точное написание
2. filter_and_aggregate(
     filters=[{"column": "Клиент", "value": "Ромашка"}, 
              {"column": "Дата", "operator": ">=", "value": "2024-10-01"}],
     operation="mean",
     target_column="Сумма"
   ) → получить результат
```

Агент выполнил задачу за 2 запроса вместо загрузки 100 МБ данных в контекст.

### 1.2. Универсальность и расширяемость

Сервер проектируется как **универсальный инструмент** для работы с любыми табличными данными, а не как специализированное решение для конкретной предметной области (логистика, финансы, HR и т.д.).

**Принципы универсальности:**
- Отсутствие хардкода специфичных для домена терминов или структур
- Динамическое определение структуры таблицы (имена колонок, типы данных)
- Поддержка произвольного количества листов, колонок, строк
- Гибкая система фильтрации без ограничений на количество условий

**Расширяемость:** Каждая новая аналитическая функция добавляется как отдельный инструмент (tool) без изменения существующего ядра. Модульная архитектура позволяет добавлять специализированные операции (например, корреляционный анализ, поиск аномалий) без нарушения работы базовых примитивов.

### 1.3. Разделение ответственности: интеллект vs исполнение

**Агент (LLM):** Планирование, декомпозиция задачи, интерпретация результатов, коммуникация с пользователем.

**MCP-сервер:** Детерминированное выполнение операций, математически точные расчеты, генерация динамических Excel-формул.

**Критическое правило:** Сервер не пытается "понять" задачу пользователя. Он только выполняет конкретные инструкции агента. Это исключает галлюцинации и обеспечивает предсказуемость результатов.

### 1.4. Философия динамических результатов

Результаты анализа должны быть **живыми**, а не статичными снимками данных. Когда пользователь копирует результат в Excel, он получает не просто числа, а **формулы**, которые автоматически пересчитываются при изменении исходных данных.

**Зона ответственности MCP-сервера:**
- Генерация корректных Excel-формул с точными ссылками на диапазоны
- Формирование TSV-вывода, готового для вставки через Ctrl+V
- Обеспечение синхронизации между JSON-результатом (для агента) и Excel-формулами (для пользователя)

**Зона ответственности модели:**
- Решение, какую информацию показать пользователю (число, таблицу, формулу)
- Форматирование вывода в читаемом виде

**Пример вывода сервера:**
```json
{
  "result": {
    "value": 15,
    "operation": "count"
  },
  "excel_output": {
    "tsv": "Клиент\tКоличество\nРомашка\t=COUNTIF(Sheet1!$A:$A,\"Ромашка\")",
    "formula": "=COUNTIF(Sheet1!$A:$A,\"Ромашка\")",
    "references": {
      "sheet": "Sheet1",
      "column": "A",
      "range": "A:A"
    }
  }
}
```

Пользователь копирует TSV → вставляет в Excel → формула работает динамически.

### 1.5. Детерминированность и надежность

**Принцип:** Результаты расчетов должны быть математически точными и воспроизводимыми. Одинаковый запрос к одинаковым данным всегда возвращает одинаковый результат.

**Гарантии:**
- Использование проверенных библиотек (Pandas) для вычислений
- Строгая типизация входных параметров (Pydantic)
- Валидация данных на всех этапах
- Отсутствие эвристик и "умных догадок" — только явные инструкции

**Обработка ошибок:** Сервер возвращает структурированные ошибки с точным описанием проблемы, а не пытается "исправить" некорректный запрос.

---

## 2. Управление состоянием (State Management)

### 2.1. Архитектурное решение: Stateless + LRU Cache

Сервер реализует **stateless архитектуру** с автоматическим кешированием. Агент не управляет сессиями и не хранит токены — он просто передает путь к файлу в каждом запросе.

**Почему stateless:**
- **Простота для агента:** Не нужно отслеживать session ID или состояние соединения
- **Надежность:** Нет проблем с "потерянными сессиями" или таймаутами
- **Масштабируемость:** Легко добавить балансировку нагрузки в будущем
- **Универсальность:** Работает одинаково через STDIO и SSE

**Как работает кеширование:**
```python
# Псевдокод внутренней логики сервера
cache = LRUCache(max_size=5)  # Хранит последние 5 файлов

def load_file(file_path: str) -> DataFrame:
    file_hash = compute_hash(file_path, file_mtime)
    
    if file_hash in cache:
        return cache[file_hash]  # Мгновенный возврат из памяти
    
    # Файл не в кеше - загружаем с диска
    df = pandas.read_excel(file_path, engine='auto')
    cache[file_hash] = df
    return df
```

### 2.2. Механизм кеширования

**Ключ кеша:** Комбинация абсолютного пути к файлу и времени последней модификации (mtime).

**Преимущества:**
- Если файл изменился на диске — сервер автоматически перечитает его
- Если агент работает с одним файлом — все запросы используют кеш
- Если агент переключается между файлами — кеш хранит несколько последних

**Размер кеша:** По умолчанию 5 файлов. Настраивается через переменную окружения `MCP_CACHE_SIZE`.

**Политика вытеснения:** LRU (Least Recently Used). Когда кеш заполнен, удаляется файл, к которому дольше всего не обращались.

### 2.3. Управление памятью

**Проблема:** Excel-файлы могут быть большими (100+ МБ). Хранение 5 файлов в памяти может занять 500+ МБ RAM.

**Решение:**

1. **Мониторинг памяти:**
```python
import psutil

def check_memory_usage():
    process = psutil.Process()
    memory_mb = process.memory_info().rss / 1024 / 1024
    
    if memory_mb > MAX_MEMORY_MB:
        cache.clear_oldest()  # Принудительная очистка
```

2. **Lazy loading колонок:**
Сервер не загружает все колонки сразу. Если запрос касается только 2 колонок из 50 — загружаются только они.

3. **Автоматическая очистка:**
- При простое более 10 минут — кеш очищается полностью
- При достижении лимита памяти (по умолчанию 1 ГБ) — удаляются старые файлы

### 2.4. Поддержка транспортных протоколов

MCP-сервер поддерживает два режима работы:

**STDIO (локальный режим):**
```bash
# Агент запускает процесс
python mcp_server.py

# Общение через stdin/stdout (JSON-RPC)
```

**Преимущества:**
- Максимальная безопасность (нет сетевого доступа)
- Нет задержек сети
- Автоматический запуск/остановка вместе с агентом

**SSE (Server-Sent Events, сетевой режим):**
```bash
# Сервер запускается отдельно
uvicorn mcp_server:app --host 127.0.0.1 --port 8000

# Агент подключается по HTTP
```

**Преимущества:**
- Один сервер для нескольких агентов
- Возможность удаленного доступа (в локальной сети)
- Легче отлаживать (можно использовать Swagger UI)

**Архитектурное решение:** Единая кодовая база. Транспортный слой абстрагирован через адаптеры. Логика работы с данными идентична в обоих режимах.

### 2.5. Отсутствие записи в файлы (текущая версия)

**Принцип:** Сервер работает в режиме **read-only**. Никакие операции не изменяют исходные файлы.

**Обоснование:**
- Безопасность: исключена случайная порча данных
- Совместимость: работа с legacy форматом .xls без риска потери данных
- Простота: не нужна сложная логика транзакций и откатов

**Будущее расширение:** Архитектура допускает добавление операций записи для .xlsx файлов. Это будут отдельные инструменты с явным подтверждением от пользователя.

**Альтернатива записи:** Генерация динамических Excel-формул, которые пользователь вставляет вручную. Это обеспечивает полный контроль и прозрачность.

---

## 3. Атомарные операции (Примитивы)

### 3.1. Принцип композиции

Все сложные аналитические задачи решаются комбинацией базовых операций. Каждая операция:
- Принимает четко определенные параметры
- Возвращает структурированный результат (JSON + Excel-формулы)
- Не имеет побочных эффектов (read-only)
- Работает с произвольным количеством сущностей (колонок, строк, листов)

**Критическое правило:** Никаких хардкодов. Если операция работает с колонками — она должна принимать список произвольной длины, а не фиксированное количество параметров.

### 3.2. Категория A: Инспекция и навигация

**A1. `inspect_file`**
```json
{
  "tool": "inspect_file",
  "params": {
    "file_path": "/path/to/file.xlsx"
  }
}
```
**Возвращает:**
- Список всех листов в файле
- Для каждого листа: количество строк, количество колонок
- Формат файла (.xls или .xlsx)
- Размер файла

**A2. `get_sheet_info`**
```json
{
  "tool": "get_sheet_info",
  "params": {
    "file_path": "/path/to/file.xlsx",
    "sheet_name": "Sheet1"
  }
}
```
**Возвращает:**
- Список имен колонок (с учетом auto-header detection)
- Типы данных каждой колонки (int, float, string, datetime)
- Количество строк с данными
- Индекс строки, где начинаются данные (после заголовков)
- Пример первых 3 строк

**A3. `get_column_names`**
```json
{
  "tool": "get_column_names",
  "params": {
    "file_path": "/path/to/file.xlsx",
    "sheet_name": "Sheet1"
  }
}
```
**Возвращает:** Простой список имен колонок. Быстрая операция для случаев, когда нужны только названия.

**A4. `find_column`**
```json
{
  "tool": "find_column",
  "params": {
    "file_path": "/path/to/file.xlsx",
    "column_name": "Клиент",
    "search_all_sheets": true
  }
}
```
**Возвращает:** Список листов, где найдена колонка с таким именем. Критично для multi-sheet операций.

### 3.3. Категория B: Получение уникальных значений

**B1. `get_unique_values`**
```json
{
  "tool": "get_unique_values",
  "params": {
    "file_path": "/path/to/file.xlsx",
    "sheet_name": "Sheet1",
    "column": "Клиент",
    "limit": 100
  }
}
```
**Возвращает:**
- Массив уникальных значений
- Количество уникальных значений
- Флаг `truncated: true`, если значений больше лимита

**Назначение:** Предотвращение ошибок фильтрации. Агент узнает точное написание значений перед построением фильтров.

**B2. `get_value_counts`**
```json
{
  "tool": "get_value_counts",
  "params": {
    "file_path": "/path/to/file.xlsx",
    "sheet_name": "Sheet1",
    "column": "Статус",
    "top_n": 10
  }
}
```
**Возвращает:** Топ-N значений с их частотой. Аналог Excel-фильтра с галочками.

### 3.4. Категория C: Фильтрация и подсчет

**C1. `filter_and_count`**
```json
{
  "tool": "filter_and_count",
  "params": {
    "file_path": "/path/to/file.xlsx",
    "sheet_name": "Sheet1",
    "filters": [
      {"column": "Клиент", "operator": "in", "values": ["Ромашка", "Лютик"]},
      {"column": "Сумма", "operator": ">", "value": 1000}
    ],
    "logic": "AND"
  }
}
```
**Возвращает:**
- Количество строк, удовлетворяющих условиям
- Excel-формула для динамического подсчета

**C2. `filter_and_get_rows`**
```json
{
  "tool": "filter_and_get_rows",
  "params": {
    "file_path": "/path/to/file.xlsx",
    "sheet_name": "Sheet1",
    "filters": [...],
    "columns": ["Клиент", "Сумма", "Дата"],
    "limit": 50,
    "offset": 0
  }
}
```
**Возвращает:** Отфильтрованные строки в виде массива объектов. Используется, когда агенту нужны сами данные (например, для построения графика).

### 3.5. Категория D: Агрегация

**D1. `aggregate`**
```json
{
  "tool": "aggregate",
  "params": {
    "file_path": "/path/to/file.xlsx",
    "sheet_name": "Sheet1",
    "operation": "sum",
    "target_column": "Сумма",
    "filters": [...]
  }
}
```
**Поддерживаемые операции:** `sum`, `mean`, `median`, `min`, `max`, `std`, `var`, `count`

**Возвращает:**
- Числовой результат
- Excel-формула (например, `=SUMIF(...)`)

**D2. `group_by`**
```json
{
  "tool": "group_by",
  "params": {
    "file_path": "/path/to/file.xlsx",
    "sheet_name": "Sheet1",
    "group_columns": ["Клиент", "Месяц"],
    "agg_column": "Сумма",
    "agg_operation": "sum",
    "filters": []
  }
}
```
**Возвращает:** Таблицу с группировкой. Аналог Pivot Table.

**Критично:** Поддержка произвольного количества колонок группировки (1, 2, 5, 10 — без ограничений).

### 3.6. Категория E: Статистический анализ

**E1. `correlate`**
```json
{
  "tool": "correlate",
  "params": {
    "file_path": "/path/to/file.xlsx",
    "sheet_name": "Sheet1",
    "columns": ["Сумма", "Количество", "Скидка"],
    "method": "pearson",
    "filters": []
  }
}
```
**Возвращает:** Матрицу корреляций между указанными колонками.

**Поддержка N колонок:** Агент может запросить корреляцию между 2, 3, 10 колонками — сервер вернет полную матрицу.

**E2. `get_column_stats`**
```json
{
  "tool": "get_column_stats",
  "params": {
    "file_path": "/path/to/file.xlsx",
    "sheet_name": "Sheet1",
    "column": "Сумма",
    "filters": []
  }
}
```
**Возвращает:** Полную статистику: min, max, mean, median, std, quartiles, outliers.

**E3. `detect_outliers`**
```json
{
  "tool": "detect_outliers",
  "params": {
    "file_path": "/path/to/file.xlsx",
    "sheet_name": "Sheet1",
    "column": "Сумма",
    "method": "iqr",
    "threshold": 1.5
  }
}
```
**Возвращает:** Список строк с выбросами и их индексы.

### 3.7. Категория F: Multi-sheet операции

**F1. `compare_sheets`**
```json
{
  "tool": "compare_sheets",
  "params": {
    "file_path": "/path/to/file.xlsx",
    "sheet1": "Январь",
    "sheet2": "Февраль",
    "key_column": "Клиент",
    "compare_columns": ["Сумма", "Количество"]
  }
}
```
**Возвращает:** Разницу между листами по указанным колонкам.

**F2. `search_across_sheets`**
```json
{
  "tool": "search_across_sheets",
  "params": {
    "file_path": "/path/to/file.xlsx",
    "column_name": "Клиент",
    "value": "Ромашка"
  }
}
```
**Возвращает:** Список листов и количество вхождений значения на каждом листе.

### 3.8. Категория G: Валидация данных

**G1. `find_duplicates`**
```json
{
  "tool": "find_duplicates",
  "params": {
    "file_path": "/path/to/file.xlsx",
    "sheet_name": "Sheet1",
    "columns": ["Клиент", "Дата"]
  }
}
```
**Возвращает:** Строки-дубликаты по указанным колонкам.

**G2. `find_nulls`**
```json
{
  "tool": "find_nulls",
  "params": {
    "file_path": "/path/to/file.xlsx",
    "sheet_name": "Sheet1",
    "columns": ["Клиент", "Сумма"]
  }
}
```
**Возвращает:** Количество и индексы строк с пустыми значениями.

---

## 4. Система фильтрации

### 4.1. Архитектура фильтров

Система фильтрации построена на принципе **композиции условий**. Агент может комбинировать произвольное количество условий с логическими операторами AND/OR.

**Базовая структура фильтра:**
```json
{
  "column": "Клиент",
  "operator": "==",
  "value": "Ромашка"
}
```

### 4.2. Поддерживаемые операторы

**Операторы сравнения:**
- `==` — равно
- `!=` — не равно
- `>` — больше
- `<` — меньше
- `>=` — больше или равно
- `<=` — меньше или равно

**Операторы множеств:**
- `in` — значение входит в список (аналог Excel-фильтра с галочками)
- `not_in` — значение не входит в список

**Операторы строк:**
- `contains` — содержит подстроку
- `startswith` — начинается с
- `endswith` — заканчивается на
- `regex` — соответствует регулярному выражению

**Операторы для null:**
- `is_null` — значение пустое
- `is_not_null` — значение не пустое

### 4.3. Примеры фильтров

**Простой фильтр:**
```json
{
  "filters": [
    {"column": "Клиент", "operator": "==", "value": "Ромашка"}
  ]
}
```

**Множественный выбор (Excel-like):**
```json
{
  "filters": [
    {"column": "Статус", "operator": "in", "values": ["Выполнен", "В работе", "Отменен"]}
  ]
}
```

**Комбинация условий (AND):**
```json
{
  "filters": [
    {"column": "Клиент", "operator": "==", "value": "Ромашка"},
    {"column": "Сумма", "operator": ">", "value": 1000},
    {"column": "Дата", "operator": ">=", "value": "2024-01-01"}
  ],
  "logic": "AND"
}
```

**Комбинация условий (OR):**
```json
{
  "filters": [
    {"column": "Статус", "operator": "==", "value": "Срочно"},
    {"column": "Сумма", "operator": ">", "value": 10000}
  ],
  "logic": "OR"
}
```

**Сложная логика (вложенные группы):**
```json
{
  "filters": [
    {
      "group": [
        {"column": "Клиент", "operator": "in", "values": ["Ромашка", "Лютик"]},
        {"column": "Статус", "operator": "==", "value": "Выполнен"}
      ],
      "logic": "AND"
    },
    {
      "group": [
        {"column": "Сумма", "operator": ">", "value": 5000}
      ]
    }
  ],
  "logic": "OR"
}
```
Читается как: `(Клиент IN ['Ромашка', 'Лютик'] AND Статус == 'Выполнен') OR (Сумма > 5000)`

### 4.4. Валидация фильтров

Сервер выполняет строгую валидацию:

1. **Проверка существования колонки:** Если колонка не существует — возвращается ошибка с списком доступных колонок
2. **Проверка типов:** Нельзя применить оператор `>` к строковой колонке
3. **Проверка значений:** Для оператора `in` обязателен параметр `values` (массив)
4. **Проверка логики:** Параметр `logic` может быть только `AND` или `OR`

**Пример ошибки:**
```json
{
  "error": "ColumnNotFound",
  "message": "Колонка 'Клиенты' не найдена",
  "available_columns": ["Клиент", "Сумма", "Дата", "Статус"],
  "suggestion": "Возможно, вы имели в виду 'Клиент'?"
}
```

### 4.5. Оптимизация фильтрации

**Векторизация:** Все операции фильтрации выполняются через Pandas векторные операции, а не через циклы Python.

**Индексация:** Для часто используемых колонок (определяется автоматически) создаются индексы для ускорения фильтрации.

**Ленивые вычисления:** Если запрашивается только количество строк — сервер не материализует отфильтрованный DataFrame, а использует `len()`.

**Кеширование результатов фильтрации:** Если агент применяет одинаковые фильтры несколько раз подряд — результат берется из кеша.

### 4.6. Генерация Excel-формул из фильтров

Сервер автоматически транслирует фильтры в Excel-формулы:

**Простой фильтр:**
```
Фильтр: {"column": "Клиент", "operator": "==", "value": "Ромашка"}
Формула: =COUNTIF(Sheet1!$A:$A,"Ромашка")
```

**Множественный выбор:**
```
Фильтр: {"column": "Статус", "operator": "in", "values": ["Выполнен", "В работе"]}
Формула: =SUMPRODUCT((Sheet1!$B:$B="Выполнен")+(Sheet1!$B:$B="В работе"))
```

**Комбинация условий:**
```
Фильтры: [
  {"column": "Клиент", "operator": "==", "value": "Ромашка"},
  {"column": "Сумма", "operator": ">", "value": 1000}
]
Формула: =SUMIFS(Sheet1!$C:$C,Sheet1!$A:$A,"Ромашка",Sheet1!$B:$B,">1000")
```

Это обеспечивает динамическую связь результатов с исходными данными.

---

## 5. Работа с несколькими листами (Multi-Sheet Operations)

### 5.1. Философия multi-sheet анализа

Реальные Excel-файлы часто содержат данные, распределенные по нескольким листам. Агент должен иметь возможность:
- Найти нужную колонку, не зная заранее на каком листе она находится
- Сравнить данные между листами
- Агрегировать данные с нескольких листов

**Принцип:** Агент не должен делать N запросов для N листов. Сервер предоставляет операции, работающие сразу со всеми листами.

### 5.2. Поиск по всем листам

**Сценарий:** Пользователь спрашивает "Сколько заказов у клиента Ромашка?", но не знает на каком листе находятся данные.

**Решение:**
```json
{
  "tool": "find_column",
  "params": {
    "file_path": "/path/to/file.xlsx",
    "column_name": "Клиент",
    "search_all_sheets": true
  }
}
```

**Возвращает:**
```json
{
  "found_in": [
    {"sheet": "Январь", "column_index": 0, "row_count": 150},
    {"sheet": "Февраль", "column_index": 0, "row_count": 142},
    {"sheet": "Архив", "column_index": 1, "row_count": 5000}
  ]
}
```

Агент видит, что колонка есть на 3 листах, и может спросить пользователя или применить фильтр ко всем листам сразу.

### 5.3. Агрегация по нескольким листам

**Инструмент: `aggregate_across_sheets`**
```json
{
  "tool": "aggregate_across_sheets",
  "params": {
    "file_path": "/path/to/file.xlsx",
    "sheets": ["Январь", "Февраль", "Март"],
    "operation": "sum",
    "target_column": "Сумма",
    "filters": [{"column": "Клиент", "operator": "==", "value": "Ромашка"}]
  }
}
```

**Возвращает:**
- Общую сумму по всем листам
- Разбивку по листам
- Excel-формулу: `=SUM(Январь!C:C,Февраль!C:C,Март!C:C)` с учетом фильтров

### 5.4. Сравнение структуры листов

**Инструмент: `compare_sheet_structures`**
```json
{
  "tool": "compare_sheet_structures",
  "params": {
    "file_path": "/path/to/file.xlsx",
    "sheets": ["Sheet1", "Sheet2"]
  }
}
```

**Возвращает:**
- Общие колонки
- Уникальные колонки для каждого листа
- Различия в типах данных

**Назначение:** Проверка совместимости листов перед объединением данных.

---

## 6. Работа с форматом .xls

### 6.1. Проблема legacy формата

Формат .xls (Excel 97-2003) является бинарным и закрытым. Его редактирование программными средствами без COM-объектов Microsoft Excel:
- Приводит к потере форматирования
- Может повредить формулы
- Не гарантирует 100% сохранность данных

**Архитектурное решение:** Сервер работает с .xls в режиме **строго read-only**.

### 6.2. Чтение .xls файлов

**Движок:** `xlrd` версии 2.0.1+

**Процесс:**
1. Определение формата по расширению файла
2. Загрузка через `pandas.read_excel(engine='xlrd')`
3. Все операции анализа работают идентично .xlsx

**Поддержка кириллицы:** `xlrd` корректно обрабатывает кодировки, используемые в русских версиях Excel.

### 6.3. Стратегия для операций записи (будущее)

Когда в будущем потребуется добавить операции записи:

**Для .xlsx:** Прямая запись через `openpyxl`

**Для .xls:** Два варианта:

**Вариант 1: Конвертация (рекомендуется)**
```
1. Создать копию файла: report.xls → report_analyzed.xlsx
2. Выполнить операции записи в .xlsx копии
3. Вернуть пользователю путь к новому файлу
```

**Вариант 2: Только вывод формул**
```
1. Сгенерировать Excel-формулы
2. Вернуть TSV для ручной вставки пользователем
3. Исходный .xls остается нетронутым
```

**Текущая версия:** Используется только вариант 2 для всех форматов.

### 6.4. Предупреждения для пользователя

Если агент обнаруживает .xls файл, сервер возвращает в метаданных:
```json
{
  "format": "xls",
  "warning": "Файл в устаревшем формате. Операции записи недоступны.",
  "recommendation": "Рассмотрите конвертацию в .xlsx для расширенных возможностей."
}
```

Агент может показать это предупреждение пользователю.

---

## 7. Интеллектуальное определение заголовков (Auto-Header Detection)

### 7.1. Проблема

Excel-файлы часто содержат "мусор" в первых строках:
```
Строка 1: ООО "Рога и Копыта"
Строка 2: Отчет за январь 2024
Строка 3: Ответственный: Иванов И.И.
Строка 4: [пустая]
Строка 5: Клиент | Сумма | Дата
Строка 6: Ромашка | 1500 | 01.01.2024
```

Прямое чтение с первой строки приведет к тому, что колонки будут названы "ООО 'Рога и Копыта'", "Отчет за январь 2024" и т.д.

### 7.2. Алгоритм обнаружения

**Шаг 1: Предварительное сканирование**
Читаем первые 20 строк файла без указания заголовков.

**Шаг 2: Анализ заполненности (Fill Rate)**
Для каждой строки вычисляем:
```python
fill_rate = count(non_empty_cells) / total_columns
```

**Шаг 3: Анализ типовой стабильности**
Сравниваем типы данных между строками:
```python
if row[i] is string AND row[i+1] is numeric:
    # Вероятно, row[i] - заголовок, row[i+1] - данные
    header_candidate = i
```

**Шаг 4: Проверка уникальности**
Заголовки должны быть уникальными (нет дубликатов в строке).

**Шаг 5: Поиск медианной заполненности**
Находим первую строку, где `fill_rate` близок к медианному значению последующих 10 строк.

**Результат:** Индекс строки, которая является заголовком.

### 7.3. Fallback механизм

Если алгоритм не может определить заголовок однозначно (confidence < 80%):

```json
{
  "error": "AmbiguousHeader",
  "message": "Не удалось автоматически определить строку заголовков",
  "candidates": [
    {"row": 0, "preview": ["ООО Рога и Копыта", "Отчет", "..."], "confidence": 0.3},
    {"row": 4, "preview": ["Клиент", "Сумма", "Дата"], "confidence": 0.75}
  ],
  "action_required": "Укажите индекс строки заголовков вручную"
}
```

Агент показывает пользователю варианты и просит выбрать.

### 7.4. Ручное указание заголовков

Все инструменты поддерживают опциональный параметр:
```json
{
  "tool": "get_sheet_info",
  "params": {
    "file_path": "/path/to/file.xlsx",
    "sheet_name": "Sheet1",
    "header_row": 4
  }
}
```

Это переопределяет автоматическое определение.

---

## 8. Форматы вывода и генерация TSV

### 8.1. Структура ответа сервера

Каждый инструмент возвращает **двойной формат**:

```json
{
  "result": {
    // JSON для агента
    "value": 15,
    "operation": "count",
    "filters_applied": [...],
    "execution_time_ms": 45
  },
  "excel_output": {
    // Данные для пользователя
    "tsv": "Клиент\tКоличество\nРомашка\t=COUNTIF(Sheet1!$A:$A,\"Ромашка\")",
    "formula": "=COUNTIF(Sheet1!$A:$A,\"Ромашка\")",
    "references": {
      "sheet": "Sheet1",
      "column": "A",
      "range": "A:A"
    }
  },
  "metadata": {
    "file_format": "xlsx",
    "sheet_name": "Sheet1",
    "rows_processed": 1500
  }
}
```

### 8.2. Генерация TSV

**TSV (Tab-Separated Values)** — формат, который Excel понимает при вставке через Ctrl+V.

**Правила генерации:**
1. Разделитель колонок: `\t` (табуляция)
2. Разделитель строк: `\n`
3. Первая строка: заголовки колонок
4. Последующие строки: данные или формулы
5. Экранирование: кавычки внутри значений удваиваются

**Пример для таблицы:**
```
Клиент	Сумма	Формула
Ромашка	1500	=SUMIF(Sheet1!$A:$A,"Ромашка",Sheet1!$B:$B)
Лютик	2300	=SUMIF(Sheet1!$A:$A,"Лютик",Sheet1!$B:$B)
```

Пользователь копирует весь блок → Ctrl+V в Excel → получает таблицу с работающими формулами.

### 8.3. Генерация Excel-формул

**Принципы:**
1. Использование абсолютных ссылок (`$A:$A`) для стабильности
2. Корректное экранирование строковых значений
3. Поддержка русских имен листов: `'Январь 2024'!A:A`
4. Генерация формул, совместимых с Excel 2010+

**Примеры трансляции:**

**Простой подсчет:**
```
Операция: count
Фильтр: {"column": "Клиент", "value": "Ромашка"}
Формула: =COUNTIF(Sheet1!$A:$A,"Ромашка")
```

**Сумма с условием:**
```
Операция: sum
Фильтр: {"column": "Клиент", "value": "Ромашка"}
Целевая колонка: "Сумма"
Формула: =SUMIF(Sheet1!$A:$A,"Ромашка",Sheet1!$B:$B)
```

**Множественные условия:**
```
Операция: sum
Фильтры: [
  {"column": "Клиент", "value": "Ромашка"},
  {"column": "Статус", "value": "Выполнен"}
]
Формула: =SUMIFS(Sheet1!$C:$C,Sheet1!$A:$A,"Ромашка",Sheet1!$B:$B,"Выполнен")
```

**Среднее значение:**
```
Операция: mean
Фильтр: {"column": "Клиент", "value": "Ромашка"}
Формула: =AVERAGEIF(Sheet1!$A:$A,"Ромашка",Sheet1!$B:$B)
```

### 8.4. Markdown-таблицы для отчетов

Для случаев, когда агент формирует текстовый отчет, сервер также возвращает Markdown:

```markdown
| Клиент  | Количество | Сумма  |
|---------|------------|--------|
| Ромашка | 15         | 45000  |
| Лютик   | 8          | 23000  |
```
Агент может вставить это в свой ответ для красивого отображения.

---

## 9. Технологический стек

### 9.1. Основные компоненты

**Python 3.10+**
- Выбор обусловлен зрелостью экосистемы для работы с данными
- Нативная поддержка type hints для строгой типизации
- Async/await для эффективной обработки параллельных запросов

**Pandas 2.0+**
- Основной движок для манипуляции данными
- Векторизованные операции для высокой производительности
- Поддержка множества форматов (xls, xlsx, csv)

**FastAPI**
- Современный веб-фреймворк для реализации MCP-протокола
- Автоматическая генерация OpenAPI-схемы
- Встроенная валидация через Pydantic
- Поддержка как STDIO, так и SSE транспорта

**Pydantic 2.0+**
- Строгая валидация входных параметров
- Автоматическая генерация JSON-схем
- Предотвращение некорректных запросов на уровне типов

**xlrd 2.0.1+**
- Чтение legacy формата .xls
- Стабильная работа с кириллицей

**openpyxl 3.1+**
- Чтение и запись современного формата .xlsx
- Поддержка формул (для будущих операций записи)

**psutil**
- Мониторинг использования памяти
- Автоматическая очистка кеша при превышении лимитов

### 9.2. Структура проекта

```
mcp-excel/
├── src/
│   ├── core/
│   │   ├── cache.py               # LRU-кеш для файлов
│   │   ├── file_loader.py         # Загрузка и определение формата
│   │   ├── header_detector.py     # Auto-header detection
│   │   ├── datetime_detector.py   # Определение колонок с датами
│   │   └── datetime_converter.py  # Конвертация Excel-чисел в datetime
│   ├── operations/
│   │   ├── base.py            # Базовый класс с общей функциональностью
│   │   ├── inspection.py      # Категория A: инспекция + F: multi-sheet
│   │   ├── data_operations.py # Категория B-C-D: данные, фильтрация, агрегация
│   │   ├── filtering.py       # Движок фильтрации
│   │   ├── statistics.py      # Категория E: статистика
│   │   ├── validation.py      # Категория G: валидация данных
│   │   ├── timeseries.py      # Категория H: временные ряды
│   │   └── advanced.py        # Категория I-J: ранжирование и вычисления
│   ├── excel/
│   │   ├── formula_generator.py  # Генерация Excel-формул
│   │   └── tsv_formatter.py      # Форматирование TSV
│   ├── transport/
│   │   ├── stdio_adapter.py  # STDIO транспорт
│   │   └── sse_adapter.py    # SSE транспорт
│   ├── models/
│   │   ├── requests.py       # Pydantic модели запросов
│   │   └── responses.py      # Pydantic модели ответов
│   └── main.py               # Точка входа
├── tests/
│   ├── test_operations.py
│   ├── test_filters.py
│   └── fixtures/             # Тестовые Excel-файлы
├── pyproject.toml
└── README.md
```

### 9.3. Зависимости

**Обязательные:**
```toml
[tool.poetry.dependencies]
python = "^3.10"
pandas = "^2.0.0"
fastapi = "^0.109.0"
pydantic = "^2.5.0"
xlrd = "^2.0.1"
openpyxl = "^3.1.0"
psutil = "^5.9.0"
uvicorn = "^0.27.0"
```

**Опциональные (для разработки):**
```toml
[tool.poetry.group.dev.dependencies]
pytest = "^7.4.0"
pytest-asyncio = "^0.21.0"
black = "^23.12.0"
mypy = "^1.8.0"
ruff = "^0.1.0"
```

---

## 10. Безопасность и валидация

### 10.1. Валидация путей к файлам

**Проблема:** Агент может передать путь к системному файлу или файлу вне разрешенной директории.

**Решение:**
```python
ALLOWED_DIRECTORIES = [
    Path.home() / "Documents",
    Path.home() / "Desktop",
    Path.home() / "Downloads"
]

def validate_file_path(file_path: str) -> Path:
    path = Path(file_path).resolve()
    
    # Проверка существования
    if not path.exists():
        raise FileNotFoundError(f"Файл не найден: {file_path}")
    
    # Проверка расширения
    if path.suffix.lower() not in ['.xls', '.xlsx']:
        raise ValueError(f"Неподдерживаемый формат: {path.suffix}")
    
    # Проверка директории
    if not any(path.is_relative_to(allowed) for allowed in ALLOWED_DIRECTORIES):
        raise PermissionError(f"Доступ к файлу запрещен: {file_path}")
    
    return path
```

**Настройка:** Список разрешенных директорий конфигурируется через переменные окружения.

### 10.2. Ограничения на размер данных

**Защита от DoS:**
- Максимальный размер файла: 500 МБ (по умолчанию)
- Максимальное количество строк в ответе: 10,000
- Максимальное количество уникальных значений: 1,000
- Timeout на операцию: 30 секунд

**Конфигурация:**
```python
MAX_FILE_SIZE_MB = int(os.getenv("MCP_MAX_FILE_SIZE", "500"))
MAX_ROWS_RETURN = int(os.getenv("MCP_MAX_ROWS", "10000"))
OPERATION_TIMEOUT = int(os.getenv("MCP_TIMEOUT", "30"))
```

### 10.3. Изоляция ошибок

**Принцип:** Ошибки в одном запросе не должны влиять на другие запросы или состояние сервера.

**Реализация:**
- Каждый запрос обрабатывается в изолированном контексте
- Исключения перехватываются и возвращаются как структурированные ошибки
- Кеш защищен от повреждения при ошибках загрузки

**Пример обработки ошибок:**
```json
{
  "error": {
    "type": "FilterValidationError",
    "message": "Колонка 'Клиенты' не найдена",
    "details": {
      "requested_column": "Клиенты",
      "available_columns": ["Клиент", "Сумма", "Дата"],
      "suggestion": "Возможно, вы имели в виду 'Клиент'?"
    },
    "recoverable": true
  }
}
```

### 10.4. Защита от инъекций

**Excel Formula Injection:**
При генерации формул сервер экранирует все пользовательские значения:

```python
def escape_excel_value(value: str) -> str:
    # Экранирование кавычек
    value = value.replace('"', '""')
    
    # Защита от formula injection
    if value.startswith(('=', '+', '-', '@')):
        value = "'" + value
    
    return f'"{value}"'
```

**Path Traversal:**
Все пути нормализуются через `Path.resolve()` для предотвращения атак типа `../../etc/passwd`.

---

## 11. Производительность и оптимизация

### 11.1. Стратегия кеширования

**Трехуровневый кеш:**

**Уровень 1: Кеш файлов (LRU)**
- Хранит загруженные DataFrame в памяти
- Размер: 5 файлов по умолчанию
- Ключ: `(file_path, mtime)`

**Уровень 2: Кеш результатов фильтрации**
- Хранит результаты часто используемых фильтров
- Размер: 50 записей
- Ключ: `(file_hash, sheet_name, filter_hash)`
- TTL: 5 минут

**Уровень 3: Кеш метаданных**
- Хранит информацию о структуре файлов
- Размер: 100 записей
- Ключ: `(file_path, mtime)`
- TTL: 10 минут

### 11.2. Ленивые вычисления

**Принцип:** Не вычислять больше, чем запрошено.

**Примеры:**
- Если запрошен только `count` — не материализовать отфильтрованный DataFrame
- Если запрошены только имена колонок — не читать данные
- Если запрошены первые 10 строк — использовать `nrows=10` при чтении

**Реализация:**
```python
def filter_and_count(df: DataFrame, filters: List[Filter]) -> int:
    # Не создаем новый DataFrame, только считаем
    mask = build_filter_mask(df, filters)
    return mask.sum()  # Быстрее, чем len(df[mask])
```

### 11.3. Векторизация операций

**Все операции фильтрации и агрегации используют Pandas векторные операции:**

```python
# Плохо (медленно)
count = 0
for row in df.iterrows():
    if row['Клиент'] == 'Ромашка':
        count += 1

# Хорошо (быстро)
count = (df['Клиент'] == 'Ромашка').sum()
```

**Производительность:** Векторизованные операции в 10-100 раз быстрее циклов Python.

### 11.4. Параллельная обработка

**Multi-sheet операции выполняются параллельно:**

```python
import asyncio

async def aggregate_across_sheets(sheets: List[str]) -> Dict:
    tasks = [process_sheet(sheet) for sheet in sheets]
    results = await asyncio.gather(*tasks)
    return combine_results(results)
```

**Ограничение:** Максимум 10 параллельных операций для предотвращения перегрузки памяти.

### 11.5. Мониторинг производительности

**Метрики в каждом ответе:**
```json
{
  "result": {...},
  "performance": {
    "execution_time_ms": 45,
    "rows_processed": 1500,
    "cache_hit": true,
    "memory_used_mb": 12.5
  }
}
```

Агент может использовать эти метрики для оптимизации последующих запросов.

---

## 12. Расширяемость и будущее развитие

### 12.1. Добавление новых операций

**Процесс добавления нового инструмента:**

1. Создать Pydantic-модель запроса в `models/requests.py`
2. Реализовать логику в соответствующем модуле `operations/`
3. Добавить генерацию Excel-формулы в `excel/formula_generator.py`
4. Зарегистрировать инструмент в `main.py`
5. Написать тесты в `tests/`

**Пример:**
```python
# models/requests.py
class FindOutliersRequest(BaseModel):
    file_path: str
    sheet_name: str
    column: str
    method: Literal["iqr", "zscore"] = "iqr"
    threshold: float = 1.5

# operations/statistics.py
def find_outliers(request: FindOutliersRequest) -> OutliersResponse:
    df = load_file(request.file_path, request.sheet_name)
    # ... логика обнаружения выбросов
    return OutliersResponse(...)
```

### 12.2. Поддержка новых форматов

**Архитектура позволяет легко добавить поддержку:**
- CSV (с автоопределением кодировки)
- ODS (OpenDocument Spreadsheet)
- Google Sheets (через API)

**Абстракция:**
```python
class FileLoader(ABC):
    @abstractmethod
    def load(self, path: str) -> DataFrame:
        pass

class XLSXLoader(FileLoader):
    def load(self, path: str) -> DataFrame:
        return pd.read_excel(path, engine='openpyxl')

class CSVLoader(FileLoader):
    def load(self, path: str) -> DataFrame:
        encoding = detect_encoding(path)
        return pd.read_csv(path, encoding=encoding)
```

### 12.3. Операции записи (далёкое будущее)

**Когда потребуется добавить запись:**

**Новые инструменты:**
- `create_calculated_column` — добавить колонку с формулой
- `create_pivot_table` — создать сводную таблицу на новом листе
- `export_filtered_data` — сохранить отфильтрованные данные в новый файл

**Ограничения:**
- Только для .xlsx формата
- Требуется явное подтверждение от пользователя
- Создание резервной копии перед изменением

**Архитектурная подготовка:**
Текущая архитектура уже поддерживает это через:
- Разделение read/write операций на уровне модулей
- Генерацию формул (можно записать в файл вместо возврата)
- Валидацию форматов файлов

### 12.4. Интеграция с другими системами

**Потенциальные расширения:**
- Экспорт результатов в базы данных (PostgreSQL, SQLite)
- Интеграция с BI-системами (Power BI, Tableau)
- Webhook-уведомления о завершении длительных операций
- Поддержка распределенной обработки для очень больших файлов

---

---

## 14. Работа с датами и временем

### 14.1. Проблема

Excel хранит даты как числа (количество дней с 1900-01-01 для Windows или 1904-01-01 для Mac). Pandas по умолчанию не знает что это даты и возвращает `float64`:

```python
# Excel показывает: "07/02/2026 13:53"
# Pandas возвращает: 46060.7625
# Агент не понимает что это дата
```

### 14.2. Архитектурное решение: Форматы ячеек - первичный источник истины

**Принцип:** Не эвристика, не догадки. Читаем метаданные из файла.

**Алгоритм определения (в порядке приоритета):**

1. **ПЕРВИЧНО:** Читать форматы ячеек из Excel
   - Если формат содержит "dd", "mm", "yyyy" → это дата
   - Точность: 100%
   - Источник: `xl/styles.xml` для .xlsx, BIFF записи для .xls

2. **ВТОРИЧНО:** Проверять тип Pandas
   - Если Pandas определил как `datetime64` → это дата
   - Точность: 95%

3. **ТРЕТИЧНО (fallback):** Эвристика для `float64`
   - Только если форматы недоступны (поврежденный файл)
   - Проверка диапазона значений (1-60000)
   - Точность: 80-90%

### 14.3. Компоненты

**DateTimeDetector** ([`core/datetime_detector.py`](../../src/mcp_excel/core/datetime_detector.py))
- Определяет какие колонки содержат даты
- Использует форматы ячеек (первично) и эвристику (fallback)

**DateTimeConverter** ([`core/datetime_converter.py`](../../src/mcp_excel/core/datetime_converter.py))
- Конвертирует Excel-числа в `pd.Timestamp`
- Поддерживает Windows и Mac epoch
- Формула: `epoch_date + pd.Timedelta(days=excel_number)`

**Интеграция в FileLoader:**
```python
df = loader.load(file_path, sheet_name, convert_dates=True)
# Автоматическая конвертация дат
```

### 14.4. Формат возврата агенту

**Стандарт:** ISO 8601
```json
{
  "column": "Дата прибытия",
  "type": "datetime",
  "sample_values": [
    "2026-02-07T13:53:00",
    "2026-02-08T09:30:00"
  ]
}
```

---

## 15. Защита от переполнения контекста агента

### 15.1. Философия

**Проблема:** Агент не может предсказать размер ответа (не знает количество колонок, длину значений, кодировку).

**Философия:** Агенту не нужны все данные таблицы. Он не может их анализировать - для этого есть MCP-инструменты (агрегация, фильтрация, статистика). Ему нужны только **примеры данных** для понимания структуры.

### 15.2. Двухуровневая защита (Defense in Depth)

**Уровень 1: Умные дефолты (превентивная защита)**
```python
DEFAULT_COLUMN_LIMIT = 5      # Колонок по умолчанию
DEFAULT_ROW_LIMIT = 50        # Строк по умолчанию
MAX_ROW_LIMIT = 1000          # Максимум строк (жесткий лимит)
```

Если агент не указал `columns` - возвращаются только первые 5 колонок. Этого достаточно для понимания структуры.

**Уровень 2: Проверка размера (последняя линия обороны)**
```python
MAX_RESPONSE_CHARS = 50_000   # ~20k токенов для кириллицы
```

Перед возвратом ответа проверяется его размер. Если превышен лимит - выбрасывается понятная ошибка с рекомендациями.

### 15.3. BaseOperations

Базовый класс ([`operations/base.py`](../../src/mcp_excel/operations/base.py)) с общей функциональностью:

**Методы защиты:**
- `_validate_response_size()` - проверка размера ответа
- `_apply_column_limit()` - применение лимита колонок
- `_enforce_row_limit()` - применение лимита строк

**Общие методы:**
- `_format_value()` - форматирование чисел (50089416.0 → 50089416)
- `_get_performance_metrics()` - метрики производительности
- `_get_file_metadata()` - метаданные файла

Все классы операций наследуются от `BaseOperations`.

### 15.4. Затронутые инструменты

**9 критичных инструментов** (возвращают rows/groups):
- `filter_and_get_rows`, `group_by`, `find_duplicates`, `detect_outliers`
- `compare_sheets`, `rank_rows`, `calculate_expression`
- `calculate_running_total`, `calculate_moving_average`

**13 безопасных инструментов** (возвращают агрегаты) - защита не требуется.

---

## 16. Подводные камни и решения

### 16.1. Форматирование чисел для агента

**Проблема:** Pandas конвертирует в `float64` (50089416.0), агент видит несоответствие с Excel (50089416).

**Решение:** Метод `_format_value()` в `BaseOperations`:
```python
if isinstance(value, float) and value.is_integer():
    return int(value)  # 50089416.0 → 50089416
```

**Где применять:** Везде где данные возвращаются агенту (rows, groups, aggregates).

### 16.2. Типы в Pydantic

**Проблема:** Pydantic принудительно конвертирует `int` → `float` если поле имеет тип `float`.

**Решение:** Union-типы для сохранения исходного типа:
```python
value: int | float  # Вместо value: float
```

**Где:** `AggregateResponse.value`, `ColumnStats.min/max`.

### 16.3. Текстовые числа в Excel

**Проблема:** Excel часто хранит номера/артикулы как текст, Pandas определяет как `dtype='object'`.

**Решение:** Автоконвертация с проверкой потери данных:
```python
col_data_numeric = pd.to_numeric(col_data, errors='coerce')
# Если потеряли <50% данных - используем numeric версию
if non_null_converted >= non_null_original * 0.5:
    col_data = col_data_numeric
```

**Где:** `aggregate`, `group_by`, все операции с числовыми колонками.

### 16.4. Кеширование с header_row

**Проблема:** Ключ кеша должен включать `header_row`, иначе возвращаются неправильные данные.

**Решение:**
```python
cache_key = f"{sheet}::header_{header_row}::dates_{convert_dates}"
```

### 16.5. Разделение ответственности FileLoader vs Operations

**Принцип Single Responsibility:**
- **FileLoader** - низкоуровневый компонент (загружает файлы, применяет `header_row`, конвертирует datetime)
- **Operations** - бизнес-логика (определяют заголовки, вызывают FileLoader с правильными параметрами)

**Критично:** FileLoader НЕ должен автоматически определять заголовки. Это ответственность Operations.

### 16.6. Нормализация имён колонок

**Проблема:** Pandas может хранить имена колонок как `int` (0, 1, 2...).

**Решение:**
```python
df.columns = [str(col) for col in df.columns]
```

**Где:** После загрузки DataFrame, перед работой с колонками.

---

## 17. Лучшие практики

### 17.1. Векторизация операций

**Принцип:** Все операции через Pandas векторные методы, не циклы Python.

**Производительность:** В 10-100 раз быстрее циклов.

**Примеры:** `cumsum()`, `rolling().mean()`, `rank()`, `eval()`.

### 17.2. Использование готовых компонентов

- **FilterEngine:** Не писать свою фильтрацию, использовать готовый движок
- **FormulaGenerator:** Не генерировать формулы вручную
- **TSVFormatter:** Не форматировать TSV вручную

### 17.3. Безопасность вычислений

**Проблема:** `eval()` выполняет произвольный Python-код (уязвимость).

**Решение:** `pandas.eval()` - безопасен, работает только с арифметикой.

**Где:** `calculate_expression` использует `pandas.eval()`, не `eval()`.

### 17.4. Принцип владения данными (Data Ownership)

**Проблема:** Pandas различает view (представление) и copy (копию) DataFrame. Модификация view вызывает `SettingWithCopyWarning` и может привести к непредсказуемому поведению.

**Архитектурный принцип:** Операции, которые **сокращают** набор данных (фильтрация, выборка), должны возвращать **копию** DataFrame. Вызывающий код владеет результатом и может его свободно модифицировать.

**Реализация в FilterEngine:**

```python
def apply_filters(self, df: pd.DataFrame, filters: list[FilterCondition], logic: str = "AND") -> pd.DataFrame:
    """Apply filters to DataFrame.
    
    Returns:
        NEW DataFrame (copy) containing filtered rows. Caller owns the result.
    """
    if not filters:
        return df  # No filters = no copy needed
    
    # ... build masks ...
    
    # Return explicit copy for clear ownership
    return df[combined_mask].copy()
```

**Обоснование:**
- Устанавливает чёткий контракт: "операции сокращения возвращают владение"
- Вызывающий код может модифицировать результат без побочных эффектов
- Исключает целый класс багов с неожиданными изменениями данных
- Применимо ко всем будущим операциям сокращения данных

**Где применяется:** `FilterEngine.apply_filters()` - единственное место, где создаётся копия. Все операции (`timeseries`, `statistics`, `advanced`) используют этот компонент и получают данные, которыми владеют.

### 17.5. Экранирование в Excel-формулах

**Проблема:** Formula injection через пользовательские значения.

**Решение:** `FormulaGenerator.escape_excel_value()` экранирует кавычки и спецсимволы.

**Защита:** Значения начинающиеся с `=`, `+`, `-`, `@` префиксируются апострофом.

### 17.6. Динамическое количество параметров

**Проблема:** Хардкод количества колонок (например, `group_by` только для 2 колонок).

**Решение:** Все операции принимают списки произвольной длины.

**Примеры:** `group_by(group_columns=[...])`, `correlate(columns=[...])`.

### 17.7. Генерация букв колонок Excel

**Проблема:** `chr(65 + col_idx)` работает только для A-Z (26 колонок).

**Решение:** Метод `_column_letter()` поддерживает AA, AB, ZZ и далее.

**Где:** `FormulaGenerator`, все операции генерирующие формулы.

### 17.8. Инициализация FormulaGenerator

**Проблема:** `FormulaGenerator` требует `sheet_name` в конструкторе.

**Решение:** Создавать в методе, не в `__init__`:
```python
formula_gen = FormulaGenerator(request.sheet_name)
```

**Почему:** `sheet_name` нужен для генерации ссылок типа `Sheet1!A:A`.

---

## 18. Заключение

Данная архитектура обеспечивает:

✅ **Универсальность** — работа с любыми табличными данными без привязки к домену
✅ **Детерминированность** — математически точные результаты без галлюцинаций
✅ **Эффективность** — минимальное количество запросов для решения задач
✅ **Динамичность** — результаты в виде Excel-формул, а не статичных значений
✅ **Безопасность** — строгая валидация и изоляция ошибок
✅ **Расширяемость** — легкое добавление новых операций
✅ **Производительность** — кеширование, векторизация, параллелизм
✅ **Защита контекста** — умные дефолты предотвращают переполнение контекста агента
✅ **Работа с датами** — корректное определение и конвертация datetime-колонок

MCP-сервер становится надежным мостом между интеллектом LLM и детерминированной обработкой данных, позволяя агентам эффективно работать с Excel-файлами любой сложности.


